# ğŸ”§ Predictive Maintenance Audit â€” AI4I Case Study

This case study demonstrates symbolic drift detection using Digamma Prime on the AI4I 2020 predictive maintenance dataset. We simulate controlled drift and compare traditional performance metrics (AUC) with symbolic metrics (Ï† and Î”Ï†).

---

## ğŸ“ Dataset

- **Source**: AI4I 2020 Predictive Maintenance Dataset
- **Target**: Unified binary failure indicator (`Failure`)
- **Features**: Sensor readings, operational settings, and product type

---

## ğŸ§ª Experiment Setup

- **Model**: Random Forest Classifier (100 trees)
- **Drift Simulation**: Additive shift to `"Torque [Nm]"` across test set
- **Sweep Range**: Drift magnitude from `0.0Ïƒ` to `1.0Ïƒ` in 0.1 increments

---

## ğŸ“Š Results Summary

| Metric        | Value         |
|---------------|---------------|
| Baseline AUC  | 0.999997      |
| Drifted AUC   | 0.999995      |
| Ï†             | 0.0015        |
| Î”Ï†            | 0.0014        |

- **Ï† vs Drift**: Structural divergence increases non-linearly  
- **Î”Ï† vs Drift**: Slope sensitivity tracks rate of change  
- **AUC vs Drift**: Performance remains high until ~0.5Ïƒ, then drops

---

## ğŸ“ˆ Visuals

Plots generated:
- `Ï† vs drift magnitude`
- `Î”Ï† vs drift magnitude`
- `AUC vs drift magnitude`

Saved in:
docs/case_studies/predictive_maintenance_ai4i/results/


---

## ğŸ§  Interpretation

Symbolic metrics detect drift **before** performance degrades. This confirms Digamma Primeâ€™s ability to surface early warnings in model behavior, even when traditional metrics remain stable.

---

## ğŸ” Next Steps

- Feature sensitivity sweep  
- Retraining on drifted data  
- Cross-model comparison  
- Integration into audit dashboard

---

## ğŸ§© Reproducibility

All code, data, and results are versioned and modular. See:
dp_predictive_maintenance_ai4i.py symbolic_drift_sweep.csv


## ğŸ”§ Case Study Included

See `docs/case_studies/predictive_maintenance_ai4i/` for a full symbolic drift audit using Digamma Prime.

Includes:
- `ai4i2020.csv` (example dataset)
- `dp_predictive_maintenance_ai4i.py` (execution script)
- `symbolic_drift_sweep.csv` (results)
- Visuals: Ï†, Î”Ï†, AUC vs drift

ğŸ“– Full documentation available in `docs/case_studies/predictive_maintenance_ai4i/README.md`

Symbolic Audit: Predictive Maintenance (AI4I2020)
Module: symbolic_pm_ai4i.py Dataset: ai4i2020.csv Location: docs/case_studies/predictive_maintenance_ai4i/

ğŸ§  Purpose
This case study demonstrates symbolic auditing of sensor-derived failure models using the AI4I2020 dataset. It applies algebraic operators to quantify model similarity, smooth symbolic drift, and scaffold predictive structures.

ğŸ”£ Operators Used
ğ“¢[f] Scaffolding: structural comparison of symbolic models

ğ“œ[f] Mollification: smoothing via polynomial truncation

ğ“š[f, g] Symbolic Kernel: cosine similarity between symbolic expressions

ğŸ“Š Results
Symbolic Models:

xÂ² + mean(Process temperature)

xÂ² + x + std(Rotational speed)

xÂ³ + mean(Torque)

Mollified Expressions (degree â‰¤ 3):

1.0Â·xÂ² + 310.00556

1.0Â·xÂ² + 1.0Â·x + 179.2841

1.0Â·xÂ³ + 39.98691

Cosine Similarity Matrix:

CÃ³digo
[1.0,    1.0,    0.9997]
[1.0,    1.0,    0.9997]
[0.9997, 0.9997, 1.0   ]
âœ… Interpretation
High symbolic similarity between quadratic models

Slight divergence from cubic torque-based model

Mollification preserves structure while reducing drift sensitivity

ğŸ“ Files
symbolic_pm_ai4i.py: audit logic

ai4i2020.csv: raw dataset

symbolic_extensions.py: operator definitions

