# ğŸ©º Tutorial â€” Diabetes Model Audit

This tutorial shows how Digamma-Prime compares two models on health data â€” revealing symbolic differences beyond accuracy.

---

## ğŸ“¦ Dataset

Diabetes dataset (`sklearn.datasets.load_diabetes`)

---

## ğŸ§ª Models

- `LinearRegression`  
- `RandomForestRegressor`

---

## ğŸ” Audit Goal

Compare predictions from both models on the same test set using:

- Ï† â†’ structural divergence  
- Î”Ï† â†’ rate divergence  
- Bootstrap CI â†’ confidence in drift

---

## ğŸ§ª Code Snippet

```python
from epe_maria import phi, delta_phi
from sklearn.datasets import load_diabetes
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split

X, y = load_diabetes(return_X_y=True)
Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.3, random_state=42)

lr = LinearRegression().fit(Xtr, ytr)
rf = RandomForestRegressor().fit(Xtr, ytr)

phi_val = phi(lr.predict(Xte), rf.predict(Xte))
delta_val = delta_phi(lr.predict(Xte), rf.predict(Xte))

Ï† = 18.53
Î”Ï† = 25.05

ğŸ“ˆ Visuals
Ï† shows average disagreement between models

Î”Ï† reveals nonlinear behavior in RandomForest

ğŸ§  Interpretation
Ï† is high â†’ models disagree structurally

Î”Ï† is higher â†’ RandomForest bends differently across feature space

Accuracy alone wouldnâ€™t reveal this â€” symbolic audit does
