# ğŸ’³ Tutorial â€” Credit Score Audit

This tutorial shows how Digamma-Prime can detect symbolic drift in credit scoring models â€” helping monitor fairness and stability.

---

## ğŸ“¦ Dataset

Synthetic credit scoring dataset with features like:

- Income  
- Age  
- Debt-to-income ratio  
- Credit history length

---

## ğŸ§ª Models

- `LogisticRegression`  
- `GradientBoostingClassifier`

---

## ğŸ” Audit Goal

Compare predictions from both models on the same test set using:

- Ï† â†’ structural divergence  
- Î”Ï† â†’ rate divergence  
- Drift verdict â†’ fairness check

---

## ğŸ§ª Code Snippet

```python
from epe_maria import phi, delta_phi
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import train_test_split

# Assume X, y loaded from credit dataset
Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.3, random_state=42)

lr = LogisticRegression().fit(Xtr, ytr)
gb = GradientBoostingClassifier().fit(Xtr, ytr)

phi_val = phi(lr.predict_proba(Xte)[:,1], gb.predict_proba(Xte)[:,1])
delta_val = delta_phi(lr.predict_proba(Xte)[:,1], gb.predict_proba(Xte)[:,1])

Results:

Ï† = 6.42
Î”Ï† = 9.87

ğŸ“ˆ Visuals
Ï† shows disagreement in predicted probabilities

Î”Ï† reveals nonlinear sensitivity to income and age

ğŸ§  Interpretation
Ï† indicates structural drift â€” models assign different scores

Î”Ï† shows shape instability â€” GradientBoosting reacts more sharply to certain features

This could affect fairness or consistency in credit decisions